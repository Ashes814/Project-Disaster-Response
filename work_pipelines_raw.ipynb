{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03975a78-87db-470d-8a0b-349cb60066f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ETL Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce5d656c-5d4f-4930-b7ec-2263a7df9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bfb4a889-f127-4e9c-8389-89873069890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_cat_file = 'Data/disaster_categories.csv'\n",
    "dis_mes_file = 'Data/disaster_messages.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bde15b27-149e-4e0c-96fa-30f9484921cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_data(file1, file2):\n",
    "    dis_cat_df_raw = pd.read_csv(file1)\n",
    "    dis_mes_df_raw = pd.read_csv(file2)\n",
    "    \n",
    "    \n",
    "    #display('catgories information')\n",
    "    #display(dis_cat_df_raw.info())\n",
    "    #display(dis_cat_df_raw.head())\n",
    "\n",
    "    #display('message information')\n",
    "    #display(dis_mes_df_raw.info())\n",
    "    #display(dis_mes_df_raw.head())\n",
    "    \n",
    "    df_merge_raw = dis_cat_df_raw.merge(dis_mes_df_raw, on='id')\n",
    "    #display('merge data')\n",
    "    #display(df_merge_raw.head())\n",
    "    \n",
    "    one_hot_cat = df_merge_raw.categories.str.split(';', expand=True)\n",
    "    \n",
    "    \n",
    "    cat_columns = list(map(lambda x: x[:-2], one_hot_cat.iloc[:].values[0]))\n",
    "    one_hot_cat.columns = cat_columns\n",
    "    for column in cat_columns:\n",
    "        one_hot_cat[column] = one_hot_cat[column].apply(lambda x:x[-1])\n",
    "        \n",
    "    df_merge_raw.drop(['categories'], axis=1, inplace=True)\n",
    "    df_one_hot_ok = pd.concat([df_merge_raw, one_hot_cat], axis=1)\n",
    "    #display('DataFrame has been loaded!')\n",
    "    #display(df_one_hot_ok.info())\n",
    "    #display(df_one_hot_ok.head())\n",
    "    \n",
    "    df_one_hot_ok = df_one_hot_ok.drop_duplicates() # only one step for cleaning data (drop duplicates)\n",
    "    return df_one_hot_ok\n",
    "\n",
    "\n",
    "def save_data(df, database_filename):\n",
    "   \n",
    "    engine = create_engine('sqlite:///'+database_filename)\n",
    "    df.to_sql('dataset', engine, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47c0dcd1-b622-4860-9f9f-636bcd347781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # if len(sys.argv) == 4:\n",
    "    messages_filepath, categories_filepath, database_filepath = dis_cat_file, dis_mes_file, 'Data/CleanedDiseaseResponse.db'\n",
    "    \n",
    "    try:\n",
    "\n",
    "\n",
    "        print('Loading and Cleaning data')\n",
    "        for i in range(random.randrange(1,10,1)):\n",
    "            time.sleep(0.4)\n",
    "            print('.', end='')\n",
    "            time.sleep(0.4)\n",
    "            print('.', end='')\n",
    "            time.sleep(0.4)\n",
    "            print('.', end='')\n",
    "        df_loaded = load_clean_data(categories_filepath, messages_filepath)\n",
    "        print('\\n')\n",
    "        print('Data has been loaded and cleaned!!!!')\n",
    "        print(df_loaded.info())\n",
    "        print(df_loaded.head())\n",
    "\n",
    "    except:\n",
    "        raise ValueError(\"Load Data Error!\")\n",
    "\n",
    "    try:\n",
    "        print('Saving data')\n",
    "        for i in range(random.randrange(1,10,1)):\n",
    "            time.sleep(0.4)\n",
    "            print('.', end='')\n",
    "            time.sleep(0.4)\n",
    "            print('.', end='')\n",
    "            time.sleep(0.4)\n",
    "            print('.', end='')\n",
    "        save_data(df_loaded, database_filepath)\n",
    "        print('\\n')\n",
    "        print('Data has been Saved!!!!')\n",
    "    except:\n",
    "        raise ValueError(\"Save Data Error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2659fbd-2093-4c52-bde5-f35914ae9aa8",
   "metadata": {},
   "source": [
    "# Machine Learning Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660017f-e432-4a8d-9e6f-c465b0960bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
